{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Year Project - Alfred Backhouse\n",
    "## Training creative cellular automata using GANs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on server: \n",
    "ssh alfred@conway.cs.ox.ac.uk\n",
    "jupyter notebook --no-browser --port 8080\n",
    "on local: ssh -NL 8080:localhost:8080 alfred@conway.cs.ox.ac.uk\n",
    "\n",
    "Using tmux\n",
    "tmux is a terminal multiplexer that allows you to detach from a session and then reattach to it later, even after disconnecting.\n",
    "\n",
    "SSH into your GPU server.\n",
    "Start a new tmux session by running tmux new -s session_name, replacing session_name with a name of your choice.\n",
    "Run your Python script, for example, python3 myscript.py.\n",
    "Detach from the tmux session by pressing Ctrl+b followed by d.\n",
    "You can now safely disconnect from the server, and your script will continue running.\n",
    "To reattach to the session, SSH back into the server and run tmux attach -t session_name.\n",
    "\n",
    "python3 gmmn.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set some initial parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER_N = 120\n",
    "CHANNEL_N = 16 # Number of CA state channels\n",
    "CELL_FIRE_RATE = 0.5\n",
    "SEED_STD = 0.1\n",
    "batch_size = 64\n",
    "target_digit = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and image / video utities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.initializers import Initializer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from datetime import datetime\n",
    "# Get the current date in YYYYMMDD format\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(original_train_images, original_train_labels), (original_test_images, original_test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and reshape the entire dataset before splitting\n",
    "normalized_images = original_train_images.reshape(original_train_images.shape[0], -1).astype('float32') / 255\n",
    "normalized_test_images = original_test_images.reshape(original_test_images.shape[0], -1).astype('float32') / 255\n",
    "\n",
    "# Define a split ratio for the dataset\n",
    "split_ratio = 0.8  # e.g., 80% for training, 20% for validation / testing\n",
    "\n",
    "# Calculate the number of images to include in the training set\n",
    "num_train_images = int(len(normalized_images) * split_ratio)\n",
    "\n",
    "# Split the images and labels into training and test sets\n",
    "train_images = normalized_images[:num_train_images]\n",
    "train_labels = original_train_labels[:num_train_images]\n",
    "val_images = normalized_images[num_train_images:]\n",
    "val_labels = original_train_labels[num_train_images:]\n",
    "\n",
    "test_images = normalized_test_images\n",
    "test_labels = original_test_labels\n",
    "\n",
    "\n",
    "# make it train on all digits\n",
    "# train_labels = np.full(len(train_images), target_digit)\n",
    "# val_labels = np.full(len(val_labels), target_digit)\n",
    "# test_labels = np.full(len(test_labels), target_digit)\n",
    "\n",
    "# Create a TensorFlow dataset for each digit in the training set\n",
    "datasets = []\n",
    "for digit in range(10):\n",
    "    idx = train_labels == digit\n",
    "    digit_images = train_images[idx]\n",
    "    datasets.append(tf.data.Dataset.from_tensor_slices(digit_images).shuffle(1000).batch(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Check gpu\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the CA / generator model (with some utitilies for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (1, 3, 3, 80)             6480      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (1, 3, 3, 16)             1296      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7776 (30.38 KB)\n",
      "Trainable params: 7776 (30.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title CA model and utils\n",
    "def to_greyscale(x):\n",
    "    y = tf.clip_by_value(x[..., 0:1], 0.0, 1.0)\n",
    "    return y\n",
    "\n",
    "def get_living_mask(x):\n",
    "    alpha = x[:, :, :, 0:1]\n",
    "    return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
    "\n",
    "def make_seed(num_examples, channel_n=CHANNEL_N, seed_std=SEED_STD):\n",
    "    h, w = 28,28\n",
    "    seed = np.zeros([num_examples, h, w, channel_n], np.float32)\n",
    "    for i in range(h//2 - 1, h//2 + 1):\n",
    "        for j in range(w//2-1, w//2 + 1):\n",
    "            seed[:, i, j, 0] = np.random.uniform(1, 1, size = num_examples)\n",
    "            seed[:, i, j, 1:] = np.random.normal(0, seed_std, size = seed[:, i, j, 1:].shape)\n",
    "    return seed\n",
    "\n",
    "# Gaussian initialization\n",
    "class CustomInitializer(Initializer):\n",
    "    def __init__(self, mean=0.0, stddev=0.01):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, shape, dtype=np.float32):\n",
    "        return tf.random.normal(shape, mean=self.mean, stddev=self.stddev, dtype=dtype)\n",
    "\n",
    "class build_generator(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
    "        super().__init__()\n",
    "        self.channel_n = channel_n\n",
    "        self.fire_rate = fire_rate\n",
    "\n",
    "        self.perceive = tf.keras.Sequential([\n",
    "            Conv2D(80, 3, activation=tf.nn.relu, padding=\"SAME\"), # 80 filters, 3x3 kernel\n",
    "        ])\n",
    "\n",
    "        self.dmodel = tf.keras.Sequential([\n",
    "            Conv2D(80, 1, activation=tf.nn.relu),\n",
    "            Conv2D(self.channel_n, 1, activation=tf.nn.tanh,\n",
    "                kernel_initializer=tf.zeros_initializer),\n",
    "        ])\n",
    "\n",
    "        self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
    "        pre_life_mask = get_living_mask(x)\n",
    "\n",
    "        y = self.perceive(x)\n",
    "        dx = self.dmodel(y)*step_size\n",
    "        if fire_rate is None:\n",
    "            fire_rate = self.fire_rate\n",
    "        update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
    "        x += dx * tf.cast(update_mask, tf.float32)\n",
    "\n",
    "        post_life_mask = get_living_mask(x)\n",
    "        life_mask = pre_life_mask & post_life_mask\n",
    "\n",
    "        return x * tf.cast(life_mask, tf.float32)\n",
    "\n",
    "build_generator().dmodel.summary()\n",
    "\n",
    "# TODO: TRY SIGMOID, square root loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The kernel functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y, sigma_list):\n",
    "    \"\"\"Computes a Gaussian kernel between two sets of samples using multiple bandwidth parameters.\"\"\"\n",
    "    beta_list = [1.0 / (2.0 * sigma**2) for sigma in sigma_list]\n",
    "    x_expanded = tf.expand_dims(x, 1)\n",
    "    y_expanded = tf.expand_dims(y, 0)\n",
    "    kernel_val = 0.\n",
    "    for beta in beta_list:\n",
    "        beta = tf.cast(beta, tf.float32)\n",
    "        squared_diff = tf.reduce_sum(tf.square(x_expanded - y_expanded), 2)\n",
    "        kernel_val += tf.exp(-beta * squared_diff)\n",
    "    return kernel_val / tf.cast(tf.size(sigma_list), tf.float32)\n",
    "\n",
    "def compute_mmd(x, y, sigma_list=[2, 5, 10, 20, 40, 80]):\n",
    "    \"\"\"Computes the Maximum Mean Discrepancy (MMD) between two sets of samples, x and y.\"\"\"\n",
    "    x_kernel = compute_kernel(x, x, sigma_list)\n",
    "    y_kernel = compute_kernel(y, y, sigma_list)\n",
    "    xy_kernel = compute_kernel(x, y, sigma_list)\n",
    "    return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mean_exp(a):\n",
    "    \"\"\"Compute the log of the mean of exponentials of input elements.\"\"\"\n",
    "    max_ = tf.reduce_max(a, axis=1, keepdims=True)\n",
    "    return max_ + tf.math.log(tf.reduce_mean(tf.exp(a - max_), axis=1))\n",
    "\n",
    "def tensorflow_parzen_estimator(mu, sigma):\n",
    "    \"\"\"Constructs a Parzen window estimator using TensorFlow.\"\"\"\n",
    "    mu = tf.convert_to_tensor(mu, dtype=tf.float32)\n",
    "    sigma = tf.constant(sigma, dtype=tf.float32)\n",
    "    \n",
    "    def parzen_estimator(x):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        a = (tf.expand_dims(x, 1) - tf.expand_dims(mu, 0)) / sigma\n",
    "        E = log_mean_exp(-0.5 * tf.reduce_sum(tf.square(a), axis=2))\n",
    "        Z = mu.shape[1] * tf.math.log(sigma * tf.sqrt(2 * np.pi))\n",
    "        return E - Z\n",
    "    \n",
    "    return parzen_estimator\n",
    "\n",
    "def compute_log_likelihood(parzen, data, batch_size=100):\n",
    "    \"\"\"Computes log-likelihood of data given a Parzen window estimator.\"\"\"\n",
    "    n_batches = int(np.ceil(data.shape[0] / batch_size))\n",
    "    log_likelihoods = []\n",
    "    for i in range(n_batches):\n",
    "        batch = data[i*batch_size:(i+1)*batch_size]\n",
    "        log_likelihood = parzen(batch)\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "    return tf.reduce_mean(log_likelihoods)\n",
    "\n",
    "def find_best_sigma(samples, data, sigma_range, batch_size=100, verbose=True):\n",
    "    \"\"\"Finds the best sigma value over a range by optimizing log-likelihood.\"\"\"\n",
    "    best_log_likelihood = float('-inf')\n",
    "    best_sigma = 0\n",
    "    \n",
    "    for sigma in sigma_range:\n",
    "        parzen = tensorflow_parzen_estimator(samples, sigma)\n",
    "        log_likelihood = compute_log_likelihood(parzen, data, batch_size)\n",
    "        \n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_sigma = sigma\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'sigma={sigma}, log_likelihood={log_likelihood.numpy():.2f}')\n",
    "    \n",
    "    if verbose:\n",
    "        print('====================')\n",
    "        print(f'Best log_likelihood={best_log_likelihood.numpy():.2f} for sigma={best_sigma}')\n",
    "        print('')\n",
    "    \n",
    "    return best_log_likelihood, best_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, channel_n=CHANNEL_N, seed_std=SEED_STD, iter_n=ITER_N):\n",
    "    x = make_seed(16, channel_n=channel_n, seed_std=seed_std)\n",
    "    for i in range(iter_n):\n",
    "        x = model(x, training=False) \n",
    "    generated_images = x\n",
    "    fig, axes = plt.subplots(1, 16, figsize=(20, 2))\n",
    "    greyscale_images = to_greyscale(generated_images)\n",
    "    print(greyscale_images.shape)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(greyscale_images[i, :, :, 0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(f'Generated Images for Digit {target_digit}')\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(epochs, mmd_losses, parzen_log_likelihoods, parzen_eval_interval, target_digit, params):\n",
    "    \"\"\"\n",
    "    Plots and saves the training metrics including MMD Loss and Parzen Window Log Likelihood\n",
    "    for a specific target digit.\n",
    "    \n",
    "    Parameters:\n",
    "    - epochs: Total number of epochs trained.\n",
    "    - mmd_losses: List of MMD losses recorded after each epoch.\n",
    "    - parzen_log_likelihoods: List of Parzen window log likelihoods recorded at specified intervals.\n",
    "    - parzen_eval_interval: Interval at which Parzen window log likelihoods were evaluated.\n",
    "    - target_digit: The target digit for which the model was trained.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = f'evaluation/{current_date}/{target_digit}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"train_metrics\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"generated_images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"model\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"log_likelihoods\"), exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plotting MMD Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), mmd_losses, label='MMD Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MMD Loss')\n",
    "    plt.title('MMD Loss over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plotting Parzen Window Log Likelihood\n",
    "    plt.subplot(1, 2, 2)\n",
    "    epochs_evaluated = list(range(parzen_eval_interval, epochs + 1, parzen_eval_interval))\n",
    "    plt.plot(epochs_evaluated, parzen_log_likelihoods, label='Parzen Log Likelihood', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log Likelihood')\n",
    "    plt.title('Parzen Window Log Likelihood over Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    filename = os.path.join(save_dir, f'train_metrics/train_metrics_{params[\"fire_rate\"]}_{params[\"channel_n\"]}_{params[\"lr\"]}_{params[\"epochs\"]}_{params[\"iter_n\"]}_{params[\"seed_std\"]}_.png')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()  # Close the figure to free memory\n",
    "    \n",
    "    # Save the generated images\n",
    "    (fig, axes) = generate_images(params[\"model\"], params[\"model\"].channel_n, params[\"seed_std\"], params[\"iter_n\"])\n",
    "    fig.savefig(filename.replace('train_metrics/train_metrics', 'generated_images/generated_images'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = filename.replace(\"train_metrics/train_metrics\", \"model/model\")\n",
    "    params[\"model\"].save_weights(model_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_digit(target_digit, params, sigma_range=np.arange(0.1, 0.5, 0.05), parzen_eval_interval=1):\n",
    "    model = params[\"model\"]\n",
    "    optimizer = params[\"optimizer\"]\n",
    "    epochs = params[\"epochs\"]\n",
    "    seed_std = params[\"seed_std\"]\n",
    "    channel_n = model.channel_n\n",
    "    iter_n = params[\"iter_n\"]\n",
    "    \n",
    "    log_likelihood = -10000.0\n",
    "\n",
    "    digit_dataset = datasets[target_digit]\n",
    "    \n",
    "    idx = val_labels == target_digit\n",
    "    digits = val_images[idx]\n",
    "    test_data = digits[:len(digits) - len(digits) % 100]\n",
    "\n",
    "    mmd_losses = []\n",
    "    parzen_log_likelihoods = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_mmd_losses = []\n",
    "        for real_images in digit_dataset:\n",
    "            x = make_seed(batch_size, channel_n=channel_n, seed_std=seed_std)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                for i in tf.range(iter_n):\n",
    "                    x = model(x, training=True)\n",
    "                generated_images = tf.reshape(x[..., 0], [batch_size, 28*28])\n",
    "                mmd_loss = compute_mmd(real_images, generated_images)\n",
    "\n",
    "            grads = tape.gradient(mmd_loss, model.weights)\n",
    "            grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
    "            optimizer.apply_gradients(zip(grads, model.weights))\n",
    "            epoch_mmd_losses.append(mmd_loss.numpy())\n",
    "        \n",
    "        epoch_mmd_loss_avg = np.mean(epoch_mmd_losses)\n",
    "        mmd_losses.append(epoch_mmd_loss_avg)\n",
    "        \n",
    "        # Evaluate using Parzen window estimator periodically\n",
    "        if (epoch+1) % parzen_eval_interval == 0:\n",
    "            x = make_seed(test_data.shape[0], channel_n=channel_n, seed_std=seed_std)\n",
    "            for i in range(iter_n): \n",
    "                x = model(x, training=False)\n",
    "            samples = tf.reshape(x[..., 0], [x.shape[0], 28*28])\n",
    "            log_likelihood, best_sigma = find_best_sigma(samples, test_data, sigma_range, verbose=False)\n",
    "            parzen_log_likelihoods.append(log_likelihood.numpy())\n",
    "#             print(f'Epoch {epoch+1}, Parzen Log Likelihood: {log_likelihood.numpy()}')\n",
    "#             print(f'Epoch {epoch+1}, MMD Loss: {epoch_mmd_loss_avg}')\n",
    "    \n",
    "    plot_training_metrics(epochs, mmd_losses, parzen_log_likelihoods, parzen_eval_interval, target_digit, params)\n",
    "    \n",
    "    assert log_likelihood != -10000\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fire_rates\n",
      "Currently on fire_rate = 0.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m current_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m build_generator(fire_rate\u001b[38;5;241m=\u001b[39mcurrent_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfire_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], channel_n\u001b[38;5;241m=\u001b[39mcurrent_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_n\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     36\u001b[0m current_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mcurrent_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 38\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_for_digit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_digit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m likelihoods\u001b[38;5;241m.\u001b[39mappend(likelihood)\n\u001b[1;32m     40\u001b[0m param_saved_vals\u001b[38;5;241m.\u001b[39mappend(param \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;28;01melse\u001b[39;00m param\u001b[38;5;241m.\u001b[39mlearning_rate\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# Handling optimizer objects differently\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m, in \u001b[0;36mtrain_model_for_digit\u001b[0;34m(target_digit, params, sigma_range, parzen_eval_interval)\u001b[0m\n\u001b[1;32m     28\u001b[0m     generated_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m], [batch_size, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m])\n\u001b[1;32m     29\u001b[0m     mmd_loss \u001b[38;5;241m=\u001b[39m compute_mmd(real_images, generated_images)\n\u001b[0;32m---> 31\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmmd_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m grads \u001b[38;5;241m=\u001b[39m [g\u001b[38;5;241m/\u001b[39m(tf\u001b[38;5;241m.\u001b[39mnorm(g)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-8\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mweights))\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1065\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1059\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1060\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1061\u001b[0m           output_gradients))\n\u001b[1;32m   1062\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1063\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1065\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1074\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:760\u001b[0m, in \u001b[0;36m_TapeGradientFunctions._wrap_backward_function.<locals>._backward_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    758\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m input_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m backward_function_inputs:\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 760\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremapped_captures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_digit = 4\n",
    "\n",
    "params = {\n",
    "    \"fire_rate\": [0.2, 0.5, 0.8],\n",
    "    \"channel_n\": [4, 8, 16],\n",
    "    \"lr\": [1e-5, 3e-5, 1e-4, 3e-4],\n",
    "    \"epochs\": [30],\n",
    "    \"iter_n\": [70, 100, 130, 160],\n",
    "    \"seed_std\": [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "best_params = {\n",
    "    \"fire_rate\": 0.5,\n",
    "    \"channel_n\": CHANNEL_N,\n",
    "    \"model\": build_generator(),\n",
    "    \"lr\": 2e-4,\n",
    "    \"optimizer\": tf.keras.optimizers.Adam(learning_rate=2e-4),\n",
    "    \"epochs\": 30,\n",
    "    \"iter_n\": 70,\n",
    "    \"seed_std\": SEED_STD,\n",
    "}\n",
    "\n",
    "best_log_likelihood = float('-inf')\n",
    "\n",
    "for param_name, param_values in params.items():\n",
    "    print(f'Testing {param_name}s')\n",
    "    current_params = best_params.copy()\n",
    "    likelihoods = []\n",
    "    param_saved_vals = []\n",
    "\n",
    "    for param in param_values: \n",
    "        print(f\"Currently on {param_name} = {param}\")\n",
    "        current_params[param_name] = param\n",
    "\n",
    "        current_params[\"model\"] = build_generator(fire_rate=current_params[\"fire_rate\"], channel_n=current_params[\"channel_n\"])\n",
    "        current_params[\"optimizer\"] = tf.keras.optimizers.Adam(learning_rate=current_params[\"lr\"])\n",
    "\n",
    "        likelihood = train_model_for_digit(target_digit, current_params)\n",
    "        likelihoods.append(likelihood)\n",
    "        param_saved_vals.append(param if not isinstance(param, tf.keras.optimizers.Optimizer) else param.learning_rate.numpy())  # Handling optimizer objects differently\n",
    "\n",
    "        if likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = likelihood\n",
    "            best_params[param_name] = param\n",
    "            print(f\"New best {param_name} = {param} with loss {likelihood}\")\n",
    "        else:\n",
    "            print(f\"Current {param_name} = {param} with loss {likelihood}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(param_saved_vals, likelihoods, marker='o', linestyle='-')\n",
    "    plt.title(f'Log Likelihood vs. {param_name}')\n",
    "    plt.xlabel(param_name if param_name != 'optimizers' else 'Learning Rate')\n",
    "    plt.ylabel('Log Likelihood')\n",
    "    plt.grid(True)\n",
    "    \n",
    "\n",
    "    # Save the plot\n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = f'evaluation/{current_date}/{target_digit}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(save_dir, f'log_likelihoods/log_likelihood_vs_{param_name}.png')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()  # Close the figure to free memory\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image_sample(images): \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images = to_greyscale(images[:16])\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(images[i] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model):\n",
    "    \n",
    "    x = make_seed(5000)\n",
    "\n",
    "    for i in tf.range(120):\n",
    "        x = model(x, training=False)\n",
    "\n",
    "    save_dir = f'evaluation/{current_date}/{target_digit}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"image_samples\"), exist_ok=True)\n",
    "    \n",
    "    images = to_greyscale(x)\n",
    "\n",
    "    np.save(os.path.join(save_dir, \"image_samples\", f\"generated_images.npy\"), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(current_params[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 784)\n",
      "(1100, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(val_images.shape)\n",
    "idx = val_labels == target_digit\n",
    "digits = val_images[idx]\n",
    "test_data = digits[:len(digits) - len(digits) % 100]\n",
    "test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
    "print(test_data.shape)\n",
    "\n",
    "save_dir = f'evaluation/{current_date}/{target_digit}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, \"image_samples\"), exist_ok=True)\n",
    "np.save(os.path.join(save_dir, \"image_samples\", f\"original_images.npy\"), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 28, 28, 1), dtype=float32, numpy=\n",
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_originals = np.load(f'evaluation/{current_date}/{target_digit}/image_samples/original_images.npy')\n",
    "print_image_sample(saved_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "saved_images = np.load(f'evaluation/{current_date}/{target_digit}/image_samples/generated_images.npy')\n",
    "print_image_sample(saved_images)\n",
    "print(saved_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m make_seed(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(current_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter_n\u001b[39m\u001b[38;5;124m\"\u001b[39m]): \n\u001b[0;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/keras/src/engine/training.py:589\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    587\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/ML/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use the function to find the best sigma\n",
    "target_digit = 4\n",
    "idx = train_labels == target_digit\n",
    "digit_images = train_images[idx]\n",
    "data = digit_images[:1000]\n",
    "\n",
    "model = current_params[\"model\"]\n",
    "x = make_seed(data.shape[0])\n",
    "for i in range(current_params[\"iter_n\"]): \n",
    "    x = model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 16)\n",
      "(1000, 784)\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.1, log_likelihood=-3045.50\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.15000000000000002, log_likelihood=-1068.79\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.20000000000000004, log_likelihood=-491.22\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.25000000000000006, log_likelihood=-294.44\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.30000000000000004, log_likelihood=-235.45\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.3500000000000001, log_likelihood=-234.55\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.40000000000000013, log_likelihood=-260.22\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "784\n",
      "sigma=0.45000000000000007, log_likelihood=-298.38\n",
      "====================\n",
      "Best log_likelihood=-234.55 for sigma=0.3500000000000001\n",
      "\n",
      "Best Sigma: 0.3500000000000001, Log Likelihood: -234.55296325683594\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def log_mean_exp(a):\n",
    "    \"\"\"Compute the log of the mean of exponentials of input elements.\"\"\"\n",
    "    max_ = tf.reduce_max(a, axis=1, keepdims=True)\n",
    "    return max_ + tf.math.log(tf.reduce_mean(tf.exp(a - max_), axis=1))\n",
    "\n",
    "def tensorflow_parzen_estimator(mu, sigma):\n",
    "    \"\"\"Constructs a Parzen window estimator using TensorFlow.\"\"\"\n",
    "    mu = tf.convert_to_tensor(mu, dtype=tf.float32)\n",
    "    sigma = tf.constant(sigma, dtype=tf.float32)\n",
    "    \n",
    "    def parzen_estimator(x):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        a = (tf.expand_dims(x, 1) - tf.expand_dims(mu, 0)) / sigma\n",
    "        E = log_mean_exp(-0.5 * tf.reduce_sum(tf.square(a), axis=2))\n",
    "        Z = mu.shape[1] * tf.math.log(sigma * tf.sqrt(2 * np.pi))\n",
    "        print(mu.shape[1])\n",
    "        return E - Z\n",
    "    \n",
    "    return parzen_estimator\n",
    "\n",
    "def compute_log_likelihood(parzen, data, batch_size=100):\n",
    "    \"\"\"Computes log-likelihood of data given a Parzen window estimator.\"\"\"\n",
    "    n_batches = int(np.ceil(data.shape[0] / batch_size))\n",
    "    log_likelihoods = []\n",
    "    for i in range(n_batches):\n",
    "        batch = data[i*batch_size:(i+1)*batch_size]\n",
    "        log_likelihood = parzen(batch)\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "    return tf.reduce_mean(log_likelihoods)\n",
    "\n",
    "def find_best_sigma(samples, data, sigma_range, batch_size=100, verbose=True):\n",
    "    \"\"\"Finds the best sigma value over a range by optimizing log-likelihood.\"\"\"\n",
    "    best_log_likelihood = float('-inf')\n",
    "    best_sigma = 0\n",
    "    \n",
    "    for sigma in sigma_range:\n",
    "        parzen = tensorflow_parzen_estimator(samples, sigma)\n",
    "        log_likelihood = compute_log_likelihood(parzen, data, batch_size)\n",
    "        \n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_sigma = sigma\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'sigma={sigma}, log_likelihood={log_likelihood.numpy():.2f}')\n",
    "    \n",
    "    if verbose:\n",
    "        print('====================')\n",
    "        print(f'Best log_likelihood={best_log_likelihood.numpy():.2f} for sigma={best_sigma}')\n",
    "        print('')\n",
    "    \n",
    "    return best_log_likelihood, best_sigma\n",
    "\n",
    "# Example usage\n",
    "# Assuming `samples` are your generated samples and `data` is the dataset you want to evaluate\n",
    "sigma_range = np.arange(0.1, 0.5, 0.05)  # Adjust this as necessary\n",
    "\n",
    "print(x.shape)\n",
    "samples = tf.reshape(x[..., 0], [x.shape[0], 28*28])\n",
    "print(samples.shape)\n",
    "best_log_likelihood, best_sigma = find_best_sigma(samples, data, sigma_range)\n",
    "print(f\"Best Sigma: {best_sigma}, Log Likelihood: {best_log_likelihood.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more parameters\n",
    "LSTMs\n",
    "Comparison between models - gradients, norm, ablation study, baseline, \n",
    "Start writeup, read papers, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda create -n nca1 python=3.11\n",
    "conda activate nca1\n",
    "conda install -c conda-forge matplotlib\n",
    "pip install tensorflow[and-cuda]\n",
    "conda install ipykernel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
